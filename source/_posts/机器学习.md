title: 机器学习复习
author: Jie
categories:
  - 机器学习
date: 2022-11-17 15:37:54
tags:
---

> 1、k近邻算法：
> 使用sklearn中的相关函数实现鸢尾花案例的k近邻分类，尝试使用不同的k值以比较实验结果。最后，请用以下函数实现K值自动调优。
> （交叉验证，网格搜索（模型选择与调优）API：sklearn.model_selection.GridSearchCV(estimator, param_grid=None,cv=None)
>
> 2、决策树算法：
> 如图数据集，住房（1表示拥有住房，0表示没有住房）；婚姻（0表示单身，1表示已婚，2表示离异）；年收入一栏中单位为1000元；（拖欠贷款一栏0表示不拖欠，1表示拖欠）
<!-- more -->
**任务：使用sklearn的tree函数、 graphviz函数，选择合适的算法，构造并绘制决策树**

| **HOUSE** | **Marriage** | **Annual  salary** | **No  default/Default** |
| --------- | ------------ | ------------------ | ----------------------- |
| 1         | 0            | 125                | 0                       |
| 0         | 1            | 100                | 0                       |
| 0         | 0            | 70                 | 0                       |
| 1         | 1            | 120                | 0                       |
| 0         | 2            | 95                 | 1                       |
| 0         | 1            | 60                 | 0                       |
| 1         | 2            | 220                | 0                       |
| 0         | 0            | 85                 | 1                       |
| 0         | 1            | 75                 | 0                       |
| 0         | 0            | 90                 | 1                       |

**k近邻算法**

利用sklearn中自带的鸢尾花数据集，并通过KNN算法实现对鸢尾花的分类，使用不同的k值比较实验结果，最后使用以下函数实现K值自动调优。
```
sklearn.model_selection.GridSearchCV(estimator, param_grid=None,cv=None)
estimator：估计器对象
param_grid：估计器参数(dict){“n_neighbors”:[1,3,5,10]}
cv：指定几折交叉验证
```

**关键代码**
```python
# 1.获取鸢尾花的特征值，目标值
iris_data, iris_target = self.get_iris_data()
# 2.将数据分割成训练集和测试集 test_size=0.30表示将30%的数据用作测试集 random_state=0可以将数据打散后再分割
x_train, x_test, y_train, y_test = train_test_split(iris_data, iris_target, random_state=0) 
# 将数据随机打散后可以看到准确率可以达到 97%
x_train, x_test, y_train, y_test = train_test_split(iris_data, iris_target, test_size=0.30)

# 3.特征工程(对特征值进行标准化处理)
std = StandardScaler()
x_train = std.fit_transform(x_train)
x_test = std.transform(x_test) 

# 4.送入算法
print("使用不同k制进行预测")
for k in range(1, 11):
    knn = KNeighborsClassifier(n_neighbors=k)
    knn.fit(x_train, y_train)
    print(k, "准确率：", knn.score(x_test, y_test))
# 5.使用GridSearchCV函数实现K值自动调优
# 生成knn估计器
knn = KNeighborsClassifier()
# 构造超参数值
params = {"n_neighbors": [3, 5, 10]}
# 进行网格搜索
gridCv = GridSearchCV(knn, param_grid=params, cv=25)
gridCv.fit(x_train, y_train)  # 输入训练数据
# 预测准确率
print("准确率：", gridCv.score(x_test, y_test))
print("交叉验证中最好的结果：", gridCv.best_score_)
print("最好的模型：", gridCv.best_estimator_)
```

**运行截图**
![](/images/machinelearning-0.png)
![](/images/machinelearning-1.png)
![](/images/machinelearning-2.png)
![](/images/machinelearning-3.png)

**决策树算法**

首先要选择最优的划分属性，尽量使划分的样本属于同一类别，即“纯度”最高的属性。定义数据的“纯度”就成了问题的关键，主流的算法是CART算法，sklearn中DecisionTreeClassifier就是用的CART算法，其判别纯度的指标是entropy熵与Gini指数。

熵的公式为：![](/images/machinelearning-8.png)

K表示有K种类别，pi是X取第i种类的概率，实际计算直接用第i种类别所占的比例代替，熵越大，表示此时的混乱程度越大，数据越不纯。

如果利用某一种指标A=a将原数据D分为两类D1与D2之后，在这个分类下，定义此时的条件熵为：![](/images/machinelearning-9.png)

定义此时的基尼指数为：![](/images/machinelearning-10.png)

CART算法生成的决策树是二叉树，每一步只对某一个指标做出划分。如果特征是离散的取值，那么就对每个特征的每个不同的取值作为二叉树的判定标准，大于或者小于等于该值分成两类，并计算以该点分类后，新节点的信息增益或者基尼指数，以两个子节点的样本数占比进行加权计算；如果特征是连续的取值，那么以每两个相邻的特征取值的算术平均离散化。

设需要分类的数据为D，定义数据集内数据量为D，属性集S，算法的**伪代码**如下：

① 设定纯度判断阈值![](/images/machinelearning-11.png)与样本数量阈值![](/images/machinelearning-12.png)等防止树过深的参数

② 若![](/images/machinelearning-13.png))或![](/images/machinelearning-14.png)或没有特征，则停止，返回当前树，否则转③

③根据所有特征的值进行二分类，选出基尼指数最小或信息增益最大的那个特征的值作为分类依据，得到的两个子数据集D1,D2 并返回②

**关键代码**

```python
tree_model = tree.DecisionTreeClassifier(criterion='gini',
                                         max_depth=None,
                                         min_samples_leaf=1,
                                         ccp_alpha=0.0)
tree_model.fit(X, y)
dot_data = StringIO()
feature_names = ['House', 'Marriage', 'Annual salary']
target_names = ['No default', 'Default']
tree.export_graphviz(tree_model,
                     out_file=dot_data,
                     feature_names=feature_names,
                     class_names=target_names,
                     filled=True,
                     rounded=True,
                     special_characters=True)
dot_data = dot_data.getvalue()
dot_data = dot_data.replace('\n', '')
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())
graph.write_pdf("default.pdf")
```

![](/images/machinelearning-4.png)
![](/images/machinelearning-5.png)
![](/images/machinelearning-6.png)

**20Newsgroups文档分类**

基于20Newsgroups数据集，利用朴素贝叶斯算法（请尝试使用不同的分类器，如GaussianNB、MultinominalNB等），对数据集进行文本分类，结合交叉验证，对分类结果进行简要阐释。

**下载数据集**

```
news = fetch_20newsgroups(subset='all')
```

文本数据属于非结构化的数据，一般要转换成结构化的数据才能够通过机器学习算法进行分类。常见的做法是将文本转换成“文档-词项矩阵”，矩阵中的元素可以使用词频或TF-IDF值等。

首先分割训练数据和测试数据，然后采用普通统计CountVectorizer提取特征向量，然后再采用TfidfVectorizer提取文本特征向量，然后实例化一个朴素贝叶斯分类器，并将我们的训练集特征与训练集特征对应的分类结果导入到模型中并训练模型，传入测试集，进行预测，并打印预测结果与预测精度。

**关键代码**
```python
# 分割训练数据和测试数据
x_train, x_test, y_train, y_test = train_test_split(news.data, news.target, test_size=0.25, random_state=0)

# 采用普通统计CountVectorizer提取特征向量
count_vec = CountVectorizer()
x_count_train = count_vec.fit_transform(x_train)
x_count_test = count_vec.transform(x_test) 

# 采用TfidfVectorizer提取文本特征向量
tfid_vec = TfidfVectorizer()
x_tfid_train = tfid_vec.fit_transform(x_train)
x_tfid_test = tfid_vec.transform(x_test)

mnb_count = MultinomialNB()
mnb_count.fit(x_count_train, y_train)
mnb_count_y_predict = mnb_count.predict(x_count_test)
print("测试集的预测结果为：", mnb_count_y_predict)
print("准确率：", mnb_count.score(x_count_test, y_test))
print("详细的评估指标:\n", classification_report(mnb_count_y_predict, y_test))

mnb_tfid = MultinomialNB()
mnb_tfid.fit(x_tfid_train, y_train)
mnb_tfid_y_predict = mnb_tfid.predict(x_tfid_test)
print("测试集的预测结果为：", mnb_tfid_y_predict)
print("准确率：", mnb_tfid.score(x_tfid_test, y_test))
print("详细的评估指标:\n", classification_report(mnb_tfid_y_predict, y_test))

# 设置评估算法的基准
num_folds = 10
seed = 7
scoring = 'accuracy'

# 交叉验证 自动调参
param_grid = {'alpha': [0.001, 0.01, 0.1, 1.5]}
model = MultinomialNB()
kfold = KFold(n_splits=num_folds, shuffle=True, random_state=seed)
grid = GridSearchCV(estimator=model, param_grid=param_grid, scoring=scoring, cv=kfold)
grid_result = grid.fit(X=x_tfid_train, y=y_train)
print('最优：%s 使用%s' % (grid_result.best_score_, grid_result.best_params_))
```
**运行截图**
![](/images/machinelearning-16.png)
![](/images/machinelearning-17.png)
![](/images/machinelearning-18.png)

**逻辑回归与梯度下降**

1、 根据小批量梯度下降MBGD的原理，写出python函数代码。

2、 使用MBGD实现患疝气病的马存活问题的Logistic回归来预测
> 改变batch_size的大小，比较模型表现，选择最优batch_size
> 将预测结果与BGD、SGD的结果进行比较与讨论（准确度、收敛速度等）

小批量梯度下降，是对批量梯度下降以及随机梯度下降的一个折中办法。其思想是：每次迭代 使用batch_size个样本来对参数进行更新。假设 batchsize=10，样本数 m=1000。
伪代码形式为：![](/images/machinelearning-19.png)

**关键代码**

```python
def MBGD(dataSet, alpha=0.001, batch_size=10, sample=368):
    xMat = np.mat(dataSet.iloc[:, :-1].values)
    yMat = np.mat(dataSet.iloc[:, -1].values).T
    xMat = regularize(xMat)
    m, n = xMat.shape
    weights = np.zeros((n, 1))
    m = int(sample / batch_size)
    print("batch_size =", batch_size, end=" ")
    for i in range(m):
        for i in range(batch_size):
            grad = xMat.T * (xMat * weights - yMat) / batch_size
            weights = weights - alpha * grad
    return weights

def get_acc(train, test, alpha=0.001, maxCycles=5000, batch_size=10, sample=1000):
    # weights = SGD_LR(train, alpha=alpha, maxCycles=maxCycles)
    weights = MBGD(train, alpha=alpha, batch_size=batch_size, sample=sample)
    xMat = np.mat(test.iloc[:, :-1].values)
    xMat = regularize(xMat)
    result = []
    for inX in xMat:
        label = classify(inX, weights)
        result.append(label)
    retest = test.copy()
    retest['predict'] = result
    acc = (retest.iloc[:, -1] == retest.iloc[:, -2]).mean()
    print(f'模型准确率为：{acc}')
    return retest

for i in range(1, 35):
    get_acc(train, test, alpha=0.001, batch_size=i)
```

![](/images/machinelearning-20.png)
![](/images/machinelearning-21.png)
![](/images/machinelearning-22.png)
**由结果可知，最优batch_size为21**

**对比BGD与SGD：**
BGD每一次迭代时使用所有样本来进行梯度的更新，SGD是每次迭代使用一个样本来对参数进行更新，对于BGD而言，每次迭代需要计算所有样本才能对参数进行一次更新，需要求得最小值可能需要多次迭代（假设10次）。对于SGD，每次更新参数只需要一个样本。假设样本有30W个，若使用这30W个样本进行参数更新，则参数会被更新（迭代）30W次，而这期间，SGD就能保证能够收敛到一个合适的最小值上了。在收敛时，BGD计算了10×30W次，而SGD只计算了1×30W次。从迭代的次数上来看，SGD迭代的次数较少，在解空间的搜索过程看起来很盲目。而MBGD使用一个batch可以大大减小收敛所需要的迭代次数，同时可以使收敛到的结果更加接近梯度下降的效果。（设置batch_size=100时，只需要迭代3000次）

**总结**
Logistic回归的目的是寻找一个非线性函数Sigmoid的最佳拟合参数，求解过程可以由最优化算法来完成。MBGD通过矩阵运算，每次在一个batch上优化神经网络参数并不会比单个数据慢太多，每次使用一个batch可以大大减小收敛所需要的迭代次数，同时可以使收敛到的结果更加接近梯度下降的效果，且可实现并行化。

**支持向量机**

1、 使用Iris原始数据集，构建多分类SVM模型
> 尝试改变各种超参数，特别是多分类参数decision_function_shape，比较模型结果是否存在差异
> 输出各类的支持向量的个数
> 自主探究对于多分类问题，如何可视化分类结果

2、 手写数字分类

比较使用决策树、朴素贝叶斯及支持向量机同样实现手写数字分类的效果的不同，简述三种方法各自的优劣

**sklearn.svm.SVC 支持向量机参数**

```python
class sklearn.svm.SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)
•	C：正则化参数。正则化的强度与C成反比。必须严格为正。惩罚是平方的l2惩罚。(默认1.0)， 惩罚参数越小，容忍性就越大
•	kernel：核函数类型，可选‘linear’, ‘poly’, ‘rbf’, ‘sigmoid’, ‘precomputed’
•	degree：当选择核函数为poly多项式时，表示多项式的阶数。
•	gamma：可选‘scale’和‘auto’，表示为“ rbf”，“ poly”和“ Sigmoid”的内核系数。默认是'scale',gamma取值为1 / (n_features * X.var())；当选‘auto’参数时gamma取值为1 / n_features。
•	decision_function_shape：多分类的形式，1 vs 多(‘ovo’)还是1 vs 1(’ovr’)，默认’ovr’
•	probability：是否启用概率估计,默认是False。必须在调用fit之前启用此功能，因为该方法内部使用5倍交叉验证，因而会减慢该方法的速度，并且predict_proba可能与dict不一致。
•	max_iter：算法迭代的最大步数，默认-1表示无限制
•	random_state：随机种子，随机打乱样本。
```

**完整代码**
```python
from matplotlib import pyplot as plt
from sklearn import datasets
from sklearn import svm
from sklearn.model_selection import train_test_split
import numpy as np

# 加载数据集
iris = datasets.load_iris()
X = iris.data[:, :2]  # 取前两维特征
y = iris.target

# 画出数据的散点图来看看分布状况
plt.scatter(X[y == 0, 0], X[y == 0, 1], color='r', marker='o')
plt.scatter(X[y == 1, 0], X[y == 1, 1], color='b', marker='*')
plt.scatter(X[y == 2, 0], X[y == 2, 1], color='g', marker='+')
plt.xlabel('x1')
plt.ylabel('y1')
plt.show()

# 模型的训练
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.3, random_state=0)

# C是误差惩罚系数，用来调节模型方差与偏差的问题
C = 1.0
lin_svc = svm.SVC(decision_function_shape='ovo', kernel='linear', C=C).fit(X_train, y_train)  # 线性核
rbf_svc = svm.SVC(decision_function_shape='ovo', kernel='rbf', gamma='auto', C=C).fit(X_train, y_train)  # 径向基核
poly_svc = svm.SVC(decision_function_shape='ovo', kernel='poly', degree=3, C=C).fit(X_train, y_train)  # 多项式核

print("支持向量个数：",len(lin_svc.support_vectors_))
print("支持向量个数：",len(rbf_svc.support_vectors_))
print("支持向量个数：",len(poly_svc.support_vectors_))

# 模型的评估
h = .02  # 网格中的步长
x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1
y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1
xx, yy = np.meshgrid(np.arange(x_min, x_max, h),
                     np.arange(y_min, y_max, h))

titles = ['LinearSVC (linear kernel)',
          'SVC with RBF kernel',
          'SVC with polynomial (degree 3) kernel']

for i, clf in enumerate((lin_svc, rbf_svc, poly_svc)):
    # 绘出决策边界，不同的区域分配不同的颜色
    plt.subplot(2, 2, i + 1)  # 创建一个2行2列的图，并以第i个图为当前图
    plt.subplots_adjust(wspace=0.4, hspace=0.4)  # 设置子图间隔

    # 将xx和yy中的元素组成一对对坐标，作为支持向量机的输入，返回一个array
    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])

    # 把分类结果绘制出来
    Z = Z.reshape(xx.shape)  # (220, 280)
    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired,
                 alpha=0.8)  # 使用等高线的函数将不同的区域绘制出来
    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)  # cmap相当于是配色盘
    # 将训练数据以离散点的形式绘制出来
    plt.xlabel('Sepal length')
    plt.ylabel('Sepal width')
    plt.xlim(xx.min(), xx.max())
    plt.ylim(yy.min(), yy.max())
    plt.xticks(())
    plt.yticks(())
    plt.title(titles[i])

plt.show()

print("linear")
print(lin_svc.predict(X_test))
print("score:", lin_svc.score(X_test, y_test))
print("rbf")
print(rbf_svc.predict(X_test))
print("score:", rbf_svc.score(X_test, y_test))
print("poly")
print(poly_svc.predict(X_test))
print("score:", poly_svc.score(X_test, y_test))
```

![](/images/machinelearning-23.png)

**不同参数的影响**
1.	参数C和gamma都会影响支持向量的数量。参数C越大，支持向量的数量越少。
2.	当 gamma 很小时，每一个支持向量的影响范围很大，甚至可以包含整个训练集，从而使得模型受限于每一个数据点，并不能很好的反应数据的复杂性。这样结果就是模型会接近线性。当gamma 很大时，每一个支持向量的影响范围很小，导致C并不能很好地实现 regularization 从而无法避免过拟合。
3.	仅凭支持向量的数量，不能很好地说明模型是否存在过拟合（或者欠拟合）的问题。
4.	更少的支持向量占用的存储空间更小，预测速度更快。

**支持向量的个数**
![](/images/machinelearning-24.png)

**手写数字分类**

**关键代码**
```python

mnist = load_digits()
x, test_x, y, test_y = train_test_split(mnist.data, mnist.target, test_size=0.25, random_state=40)
model = svm.LinearSVC(max_iter=10000)
model.fit(x, y)
z = model.predict(test_x)
```

**对比三种算法输出的结果**
1.	SVM
优点：适合小样本、非线性、高维模式识别。
缺点：对于大规模数据开销大，不合适多分类；对缺失数据敏感；需要选择适当的核函数。
2.	决策树
优点：简单易于理解，能够处理多路输出问题。
缺点：容易过拟合；决策树的生成不稳定，微小的数据变化可能导致生成的决策树不同。
3.	KNN
优点：简单易于理解，无需训练，无需估计参数准确性高；适合多标签问题。
缺点：懒惰算法，预测慢，开销大类的样本数不平衡时准确率受影响；可解释性差。

**运行截图**
![](/images/machinelearning-25.png)
![](/images/machinelearning-26.png)
![](/images/machinelearning-27.png)

**总结**
SVM的主要思想是：建立一个超平面作为决策平面，使得正例和反例之间的隔离边缘被最大化。SVM也是结构风险最小化方法的近似实现。SVM是一种二分类模型，它的基本模型是定义在特征空间上的间隔最大的线性分类器，SVM的的学习策略就是间隔最大化，可形式化为一个求解凸二次规划的问题，也等价于正则化的合页损失函数的最小化问题。SVM的的学习算法就是求解凸二次规划的最优化算法。对于输入空间中的非线性分类问题，可以通过非线性变换将它转化为某个维特征空间中的线性分类问题，在高维特征空间中学习线性支持向量机。由于在线性支持向量机学习的对偶问题里，目标函数和分类决策函数都只涉及实例和实例之间的内积，所以不需要显式地指定非线性变换，而是用核函数替换当中的内积。
