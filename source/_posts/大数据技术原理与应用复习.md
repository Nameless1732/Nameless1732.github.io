title: 大数据技术原理与应用复习
author: Jie
tags:
categories: 
  - 期末复习
date: 2022-6-19 21:49:53
---
> **考试范围** ：  
教材:《大数据技术原理与应用》第三版 林子雨  
第1章：大数据概述 🎉  
第2章：大数据处理架构Hadoop 🎉  
第3章：分布式文件系统HDFS 🎉  
第4章：分布式数据库HBase🎉  
第5章：NoSQL数据库🎉  
第7章：MapReduce🎉  
第10章：Spark🎉  
第11章：流计算(Storm)🎉
<!-- more -->
## 第1章 大数据概述

重要知识点：  
**1、大数据的4V**  
数据量大：在Web2.0时代、网络用户数目极大，在视频、照片社交软件火热的今天，用户产生的数据量非常大。
数据类型繁多：有金融大数据、医疗大数据、城市大数据等等。  
处理速度快：1分钟，新浪微博产生2万条微博，Twitter产生10万条推文。  
价值密度低：例如监控视频的存储，没有调取监控视频时可能体现不出价值，但在使用时可能会产生很大的价值。   

**2、大数据的应用**  
智能汽车、能源、体育与娱乐等等、大数据应用非常广泛。

**3、大数据关键技术**  
数据采集与预处理、数据存储和管理（HDFS）、数据处理与分析（如MapReduce）、数据安全和隐私保护。

**4、大数据计算模式**  
批处理计算：对大规模数据的批量处理 （MapReduce、Spark）  
流计算：针对流数据的实时计算(Spark)  
图计算：针对大规模图结构的数据的处理  
查询分析计算：大规模数据的存储管理和查询分析（Hive）

**5、大数据与云计算、物联网的关系**  
云计算为大数据提供技术基础、大数据为云计算提供用武之地。  
物联网是大数据的重要来源、大数据技术为物联网数据分析提供支撑。  
云计算为物联网提供海量数据存储能力，物联网为云计算技术提供了广阔的应用控件。

## 第2章 大数据处理架构Hadoop

**1、Hadoop的核心**  
HDFS是分布式文件存储系统(Hadoop Distributed File System) 、也是Hadoop的核心。

**2、Hadoop的特性**  
高可靠性 、高效性、高可扩展性 、高容错性 、成本低 、支持操作系统与编程语言广泛

**3、HDFS常用命令**  
创建文件夹(-p 递归创建)：hadoop fs -mkdir -p /user/hadop  
显示文件内容：hadoop fs -cat hdfs文件  
文件上传：hadoop fs -put 本地 hdfs文件  
删除文件夹：hadoop fs -rm -r hdfs文件夹  
删除文件：hadoop fs -rm hdfs文件  
切换目录：hadoop fs -cd  
查看文件与目录：hadoop fs -ls -R(-R在hdfs为递归查看)  
删除空目录：hadoop fs -rmdir  
复制文件或目录：hadoop fs -cp  
移动：hadoop fs -mv  
创建文件：hadoop fs -touchz  
拉取文件：hadoop fs -get

## 第3章 分布式系统 HDFS

**1、 HDFS计算机集群结构**  
分布式文件系统把文件分布存储到多个计算机节点上、成千上万的计算机节点构成计算机集群。

**2、 HDFS的结构**  
一个默认块大小为64MB，如果一个文件小于一个数据块的大小，在分布式文件系统，它并不占用整个数据块的存储空间。  
名称节点负责文件和目录的创建、删除、和重命名等，同时管理着数据节点和文件块的映射关系。  
数据节点负责数据的存储和读取，在存储时，由名称节点分配存储位置，客户端将数据写入相应数据节点。  
为了保证数据的完整性，文件块会被赋值为多个副本存储到多个不同的节点上，而存储同一文件块的不同副本又会分布在不同的机架上。

**3、 HDFS特点**  
优点：  
兼容廉价的设备硬件。  
流数据读写：支持流式方式来访问文件。  
大数据集：单个文件可达到GB甚至TB级别  
简单的文件模型：一次写入，多次读取。  
强大的跨平台兼容性。  
缺点：  
不适合低延迟数据访问。  
无法高效存储大量小文件。  
不支持多用户写入及任意修改文件。

**4、 HDFS的相关概念（重点）**  
重点：块、名称节点和数据节点与第二名称节点。  
**块**：HDFS文件块的大小默认为64MB，一个文件会被拆分为多个块进行存储。
		(相关知识点:MapReduce中的Map任务一次只能处理一块中的数据。)  
**采用块抽象化的好处** ：支持大规模文件存储、简化系统设计、适合数据备份。  
**NameNode** 负责管理分布式文件系统的命名空间，保存了FsImage和EditLog。  
**DataNode** 负责数据的存储和读取，根据客户端和名称节点的调度进行数据的存储和检索。也会定时向名称节点汇报自己的存储块列表信息。  
		**FsImage** 用于维护文件系统树以及文件树中所有的文件和文件夹的元数据。  
		**EditLog** (操作日志文件)记录了所有针对文件的创建、删除、重命名、等操作。  

名称节点存储文件名与文件在数据节点中的位置的映射关系、但并不是持久化存储在名称节点，而是当名称节点启动时扫描分布式文件系统得到的。  
**名称节点** 启动将FsImage加载到内存->重新执行EditLog->建立新的空FsImage和EditLog->工作记录时使用新的FsImage和EditLog当变大后系统写入到总的FsImage和EditLog内（工作模式请看第二名称节点）

**第二名称节点：**  
功能：完成FsImage和EditLog的合并操作，减小EditLog文件大小。  
**EditLog和FsImage的合并操作：**  
![在这里插入图片描述](https://img-blog.csdnimg.cn/dd0eaae1ea0b4480aea677c249e1d6d9.png)

**5、 HDFS体系结构**  
主从结构  
客户端向名称节点请求文件名或者数据块号，名称节点将数据块号、数据块位置发送至客户端。  
客户端与数据节点通信进行数据的读写操作。HDFS集群只有一个名称节点，其带宽、计算性能会影响整个系统的性能。

**HDFS命名空间管理**  
HDFS集群只有一个命名空间,即/some/some/some/some… ,像Linux的文件目录结构一样。

**通信协议**  
HDFS通信协议建立在TCP/IP基础之上。  
名称节点与数据节点采用数据节点协议进行交互。  
客户端与数据节点交互通过远程过程调用(RPC)

**HDFS体系结构局限性**  
命名空间限制、性能瓶颈(原因靠名称节点)、隔离问题（一个命名空间、和一个名称节点无法做到读写权限分配等）、集群可用性(一个名称节点)

**6、 HDFS的存储原理**  
多副本冗余存储，加快了数据传输的速率、容易检查数据错误、保证数据的可靠性。

**存放策略**  
**HDFS默认的冗余复制因子是3，每一个文件块被保存到3个地方。  
（1）如果是集群内发起的写操作，则把第1个副本放置发起写操作请求的数据节点上，实现就近写入数据，如果集群外发起写操作，则在集群内选一个磁盘空间充足且CPU不太忙的数据节点，做为第1个副本的存放位置。  
（2） 第2个副本被放置在与第1个副本不同的机架的数据节点上。  
（3） 第3个副本会被放置在与第1个副本相同的机架的其他节点上。  
（4） 如果还有更多的副本、则继续从集群中随机选择数据节点进行存放。**

![在这里插入图片描述](https://img-blog.csdnimg.cn/466604362b204be596bafa82ce947854.png)

![在这里插入图片描述](https://img-blog.csdnimg.cn/7b803419bc334261a25cb605d554d591.png)

**读取策略**  
客户端请求名称节点获取文件块不同副本的存储位置，由客户端确定从哪里获取文件块。

**数据复制**  
文件在客户端被切分成多个块，名称节点返回数据节点列表。  
客户端向一个数据节点写入，同时把数据节点列表传给第一个数据节点，当第一个节点接收数据大小4KB时并像列表第二个数据接待你发起写请求，将数据写入第二个数据节点、当第二个数据节点接收到4KB时向第三个数据节点执行类似操作。最后当文件写完时，数据的复制也同时完成了。

**名称节点出错补救方案**  
一：远程挂载到NFS上  
二：运行一个第二名称节点，能够进行有限的补救(第二名称节点中由FsImage和EditLog),但还是会可能遗失拉去FsImage和EditLog后，名称节点的一系列操作。  
**数据节点出错补救方案**  
数据节点定期向名称节点发起”心跳“，没有”心跳”时，名称节点不再向其分配读写任务，且一旦发现某些块的复制因子小了，名称节点又会安排任务，进行文件块复制。  
**数据出错**  
客户端采用MD5和SHA-1校验，出错将向名称节点汇报，请求其他副本，名称节点也会定期检查块。

## 第4章 分布式数据库HBase

**1、HBase是什么?**  
一个高可靠、高性能、面向列、可伸缩的分布式数据库。  
**2、HBase与Hadoop其他部分关系。**  
使用MapReduce处理海量数据，ZooKeeper作为协同服务。HDFS底层数据存储。Pig和Hive提供高级语言支持。
**3、HBase与传统数据库对比。**  
数据类型：采用未经解释的字符串。  
数据操作：行键查询、只有简单的插入、查询、删除、清空等。  
存储模式：列式存储。  
数据索引：行键索引。  
数据维护：并不删除原来的数据。  
横向可伸缩性：面向列存储。  
缺陷：不支持事务、无法实现跨行原子性。  
**4、HBase数据模型**  
行键：任意字符串，最大64KB。  
列族、列限定符(列名，不需要提前定义好)。  
单元格，每个单元格可以存储多个版本、每个版本对应一个时间戳。  
事件戳：每次对单元格执行操作，HBase会隐式自动生成并存储一个时间戳。  
数据坐标：[行键、列族、列限定符、时间戳]  
**5、概念视图与物理视图**  
概念视图：逻辑模型，认为规定建立。  
![在这里插入图片描述](https://img-blog.csdnimg.cn/55964069cd4941e2bb97712da76e18a8.png)

物理视图：  
![在这里插入图片描述](https://img-blog.csdnimg.cn/e829129dac504db4ae103f90b982ac6f.png)

在物理视图中，空的列并不会被存储为null，而是不会存储，当请求空白的单元格时返回null。

**6、 面向列的存储**  
从严格的关系数据库角度来看，HBase并不是一个列式存储的数据库，HBase是以列族为单位进行分解的，而不是每个列都单独存储。

**7、 HBase实现原理**  
与HDFS具有很多相似之处、有一个Master节点负责HBase表的分区信息，表被分为Region存储到多个Region服务器，Master会检测Region服务器工作状态、负责性能均衡。客户端并不从Master获得数据，从ZooKeeper获得Region位置，从Region服务器中拉取数据。

**8、 表和Region、Region的定位**

![在这里插入图片描述](https://img-blog.csdnimg.cn/005436f002cc46f995fe306d996197d6.png)

**9、 HBase系统架构**  
库函数：链接到每个客户端  
客户端：缓存Region位置、与Master进行RPC通信、与Region服务器RPC通信进行数据的读写。  
Zookeeper服务器：通常由集群组成，每个Region服务器要到Zookeeper服务器注册，Zookeeper实时监控Region,Master通过Zookeeper感知Region服务器状态。  
Master服务器：管理用户对表操作、Region服务器的负载均衡、Region分裂与合并、Region迁移  
Region服务器：Region存储、向客户端提供访问接口。

**10、 Region服务器工作原理**  
![在这里插入图片描述](https://img-blog.csdnimg.cn/e4edc7914cb5478e8805b38cc32a537d.jpg)

## 第5章 NoSQL数据库

**1、 NoSQL特点**  
灵活的可扩展性、灵活的数据模型、与云计算紧密耦合。

**2、 NoSQL与Web2.0**  
无法满足海量数据的管理需求、无法满足高并发的需求、无法满足高可扩展性和高可复用性的要求。  
Web2.0网站系统通常不需要严格的数据库事务、并不要求严格的读写实时性、通常不包含大量复杂的SQL查询。

**3、 NoSQL的四大类型**  
键值数据库、列族数据库、文档数据库、图数据库。

**4、 NoSQL三大基石，CAP、BASE、最终一致性。**  
**C (Consistency) :一致性** ，指任何一个读操作总是能够读到之前完成的写操作的结果，在分布式环境中、多点数据是一致的。  
**A（Availability）：可用性** 。指快速获取数据，且可以在确定的时间内返回操作结果。  
**P（tolerance of network partition）：分区容忍性** ，当出现网络分区的情况，分离的系统可以正常运行。

**组合：**  
CA 强调一致性和可用性，可扩展性较差。  
CP 强调一致性和分区容忍性，当出现网络分区的情况时，受影响的服务需要的等待数据一致，因此在等待期间就无法对外提供服务。  
AP 在采用AP设计时，可以不完全放弃一致性，转而采用最终一致性。

**BASE**  
**A(atomicity)原子性** ：对数据的修改、要么全部执行、要么全部不执行。  
**C(Consistency)一致性** ：在事务完成时，必须是所有数据都保持一致状态。  
**I(Isolation) 隔离性** ：并发事务所作的修改必须与其他并发事务所做的改变隔离。  
**D(Durability) 持久性** ：事务完成后、对系统的影响是永久性的。

**最终一致性**  
是弱一致性的特例，允许后续的访问操作可以暂时读不到更新后的数据，但经过一段时间后，用户可以读到更新后的数据，最终一致性也是ACID的最终目的，只要最终数据是一致的就可以了，而不是每时每刻都保持实时一致性。

## 第7章 MapReduce

Hadoop MapReduce是基于谷歌MapReduce的开源实现。

大规模数据集 -> 分片小数据集 -> 处理为 -> 交给Map任务 -> 输出List() -> Map Shuffle -> Reduce
Shuffle -> 输入 -> Reduce -> 输出。

当Map任务全部结束时，才会开始Reduce任务。  
在切分大文件时没并不是真正的切分物理文件、而是利用RecordReader记录要处理数据的位置和长度。

Shuffle过程，分为Map端的Shuffle过程、和Reduce端的Shuffle过程，Shuffle是指对Map任务输出结果进行分区，排序、合并、归并等处理并交给Reduce的过程。

**Map端的Shuffle过程**  
输入数据和执行Map任务，Map输出结果写入缓存、缓存满了则进行溢写(分区、排序、合并)
生成多个溢写文件、当Map任务全部结束之前，溢写文件会被归并为一个大的磁盘文件。

Reduce任务从Map端的不同Map机器”领取”属于自己处理的那部分数据，然后对数据进行归并后交给Reduce处理。具有相同key的会被发送到同一个Reduce任务。

关于 **溢写**
，提供给MapReduce的缓存的容量是有限的，默认大小100MB。随着Map任务执行，很快写满缓存区，进行溢写操作，首先对这些键值进行分区，默认的分区方式为Hash函数对key哈希。  
“合并”是指将具有相同key的的value加起来。并非所有场景都适合合并操作。  
每次溢写操作都会生成一个新得溢写文件，写入溢写文件中得所有键值对都是经过分区和排序得。

“归并” ,溢写文件数量越来越多，最终在Map任务全部结束前，系统对所有溢写文件数据进行归并操作，具有相同key的键值被合并为一个键值，如
会被归并为一个新的键值，>。JobTracker检测Map任务，当Map任务完成时，通知Reduce任务来领取数据。然后开始Reduce端的Shuffle过程。

**Reduce端的Shuffle过程**  
从Map端读取Map任务结果，执行归并操作，，最后送给Reduce任务进行处理。  
JobTracker检测Map任务，通知Reduce任务领取数据，先放置到Reduce任务机器的缓存中，同样存在溢写操作，当溢写过程启动时，具有相同key的键值对会被归并。同样存在溢写文件的合并。  
经过多轮归并后得到若干个大文件，直接输入Reduce任务。

**WordCount实例**  
![在这里插入图片描述](https://img-blog.csdnimg.cn/6f03e9b8c4ac4b0b9a7207734c7cfc58.png)  
![在这里插入图片描述](https://img-blog.csdnimg.cn/d01e829db9b142e9921c791e39c42005.png)  
![在这里插入图片描述](https://img-blog.csdnimg.cn/361d783bf7d043e2a4ddfb0022b01da4.png)

MapReduce模型的关系上的标准运算  
选择、投影、并、交、差、自然连接  



## 第10章 Spark

**1、 什么是Spark?**  
Spark是基于内存计算的大数据并行计算框架，可用于构建大型的、低延时的数据分析应用程序.  
**2、 Spark的特点。**  
运行速度快、使用有向无环图执行引擎、支持循环数据流与内存计算。  
容易使用，支持多种编程语言。  
通用性：提供完整的技术栈，SQL查询、流式计算、机器学习等等。  
运行模式多样：可运行在集群、EC2等环境中。

**3、 Spark与Hadoop的对比**

**Hadoop缺点** ：  
（1）表达能力有限，需要转化为Map和Reduce操作。  
（2）磁盘IO开销大，需要先内存缓存写入，缓存内容溢写到磁盘。  
（3）延迟高：一次计算可能要多个MapReduce任务，任务之间设计IO开销，在前一个任务完成之前，其他任务无法开始。

**Spark优点：**  
（1） Spark计算模式也属于MapReduce，但不局限于Map和Reduce操作。  
（2） 提供内存计算、计算结果放置于内存中。  
（3） 基于DAG任务调度执行机制，由于MapReduce的迭代执行机制。

**4、 Spark生态系统**  
大数据处理主要包括3个·类型  
（1） 复杂的批量数据处理  
（2） 基于历史数据的交互式查询  
（3） 基于实时数据流的数据处理

**Spark应用场景**  
场景 时间跨度 spark生态组件  
复杂的批量数据处理 小时级 spark core  
基于历史数据的交互式查询 分钟、秒级别 Spark SQL  
实时数据流的数据处理 毫秒级、秒级别 spark streaming、structured streaming  
历史数据的数据挖掘 MLib  
图结构数据的处理 GraphX

**5、 Spark运行架构**  
RDD：一种高度受限的共享内存模型  
DAG：反应RDD之间的依赖关系  
Spark基本运行流程：

![在这里插入图片描述](https://img-blog.csdnimg.cn/8138f49ac189463192ce5afb6fe7d9e5.jpg)

6、 RDD相关原理

![在这里插入图片描述](https://img-blog.csdnimg.cn/e0b81e7b8f814fdeb7bdf33fe26a748d.png)

7、 RDD特性  
（1） 高效的容错性  
（2） 中间结果持久化道内存  
（3） 存放的数据可以是Java对象

8、 RDD之间的依赖关系  
![在这里插入图片描述](https://img-blog.csdnimg.cn/23009fabf9b04daca123495f04bdf290.jpg)

M*R个bucket M: map任务数量 R：Reduce任务数量  
Spark多个桶写入同一个文件  
Map任务产生 数据文件与索引文件，Reduce任务通过索引文件信息，获取自己应该处理的数据信息。  
Reduce任务并不进行排序，而是利用HashMap进行分类，Reduce内存必须满足存放所有其应该存储的否则内存会溢出。但内存过大时操作也会从内存到磁盘。Spark的Shuffle过程也有把数据写入到磁盘的情况。

9、 宽依赖与窄依赖  
![在这里插入图片描述](https://img-blog.csdnimg.cn/fbbfb3fc37a24bcab83532d8ad5c0068.png)

10、 阶段划分  
只有窄依赖才能完成流水线优化。Spark通过分析RDD之间的依赖关系生成DAG，再通过分析各个RDD中的分区之间的依赖关系，划分阶段。  
具体方法：在DAG中反向解析，遇到宽依赖就断开，遇到窄依赖就把当前的RDD加入当前的阶段。  
![在这里插入图片描述](https://img-blog.csdnimg.cn/c9f94041d7d748e588d8a755826a0d8e.png)

11、 RDD运行过程  
（1） 创建RDD对象  
（2） SparkContent负责计算RDD之间的依赖关系，构建DAG  
（3） DAGScheduler负责把DAG分解成多个阶段、每个阶段中包含多个任务，每个任务会被任务调度器分发给各个工作节点上的Executor去执行

## 第11章 流计算

**1、 流数据**  
（1） 快速持续到达、潜在数据量也许是无穷无尽的  
（2） 数据来源众多、格式复杂  
（3） 数据量大、但不是十分关注存储。  
（4） 注重数据的整体价值，不过分关注个别数据  
（5） 数据顺序颠倒，或者不完整，系统无法控制将要处理的新到达的数据元素的顺序。

**2、 流计算**  
MapReduce负责海量数据执行批量计算  
（1） 高性能 （2）海量式 （3）实时性 （4）分布式（5）易用性 （6）可靠性

**3、 传统数据处理与流计算对比**  
![在这里插入图片描述](https://img-blog.csdnimg.cn/e2f5697ef347440ab823703f7342da72.png)

**4、 数据处理流程详情**  
（1） 数据实时采集  
Agent：主动采集数据、并把数据推送到Collector部分  
Collector：接收多个Agent的数据，并实现有序、可靠、高性能转发  
Store：存储，一般不存储，直接发送给流计算平台进行计算

（2） 数据实时计算  
数据流入 流处理系统实时计算 计算结果与数据流出

（3） 实时查询服务  
流计算处理的数据是实时的，用户通过流处理系统获取的是实施结果，无须人为查询，系统推送给用户

**5、 流计算应用场景**  
（1） 实时分析，如用户商品推荐、广告推荐。  
（2） 实时交通，导航路线实时交通状况。

**6、 Storm**  
Storm 免费的、开源的分布式实时计算系统。

**7、 Storm的特点**  
（1） 整合性。方便地与队列系统和数据库系统进行整合  
（2） 简易的API。Storm的API在使用上简单方便。  
（3） 可扩展性。并行特点，可以部署在分布式集群。  
（4） 容错性。自动故障节点重启。  
（5） 可靠的消息处理。保证每个消息都能完整处理。  
（6） 支持各种编程语言。  
（7） 快速部署。  
（8） 开源、免费。

**8、 Storm设计思想**  
Streams:流数据是一个无限的Tuple序列。  
Spouts：流数据的源头。  
Bolts：流数据的转换过程。  
Topology：Spouts和Bolts组成的拓扑网络，流转换图。  
Stream Groupings: 告知两个Bolt之间怎样进行Tuple传递。  
ShuffleGrouping: 随机分组，随即分发Stream中的Tuple,保证每个Bolt的Task接收Tuple数量大致一致。  
FiledsGouping: 按照字段分组，保证相同字段的Tuple分配到同一个Task中。  
AllGrouping: 广播发送，每一个Task都会收到所有的Tuple.  
GlobalGrouping：全局分组，所有Tuple分到同一个Task中。  
NonGrouping： 不分组。  
DirectGrouping：直接分组，直接指定由某个Task来执行Tuple的处理。

**9、 Storm的框架设计**  
![在这里插入图片描述](https://img-blog.csdnimg.cn/567e0dfb6b1d47718e444d892f402cd4.png)

（1） 提交Topology到Storm集群  
（2） Nimbus将分配给Supervisor的任务写入Zookeeper  
（3） Supervisor从Zookeeper获取所分配的任务，并启动Worker进程。  
（4） Worker进行执行任务。

**10、 Spark Streaming**  
Spark Streaming提供 整合多种输入数据源，将实时输入数据流以时间片为单位进行拆分，经过Spark引擎处理每个时间片数据，Spark
Streaming的输入数据按照时间片分成一段一段的Dstream,每一段数据转换为Spark中的RDD,对Dstream的操作最终转变为相对应的RDD操作。  
Spark streaming无法完成毫秒级的流计算，因为其将流数据按批处理窗口大小分解为一系列的批量处理的作业。

## HBase案例题  
客户端提供访问HBase的接口，Zookeeper服务器保存-ROOT-表的地址和Master主服务器的地址，通过三层寻址找到所需的数据。Master主服务器主要负责表和Region的管理工作，Region服务器负责维护分配给自己的Region，并响应用户请求，HBase采用HDFS作为底层存储的文件系统，HDFS向HBase提供可靠的数据存储。

1.试述在Hadoop体系架构中HBase与其他组成部分的相互关系​
答： HBase利用Hadoop MapReduce来处理HBase中的海量数据，实现高性能计算；利用Zookeeper作为协同服务，实现稳定服务和失败恢复；使用HDFS作为高可靠的底层存储，利用廉价集群提供海量数据存储能力; Sqoop为HBase的底层数据导入功能，Pig和Hive为HBase提供了高层语言支持，HBase是BigTable的开源实现。

3.请阐述HBase和传统关系数据库的区别

区别|传统关系数据库|HBase
---|---|---
数据类型|关系模型|数据模型
存储模式|基于行模式存储，元组或行会被连续地存储在磁盘也中|基于列存储，每个列族都由几个文件保存，不同列族的文件是分离的
数据索引|针对不同列构建复杂的多个索引|只有一个行键索引
数据维护|用最新的当前值去替换记录中原 来的旧值|更新操作不会删除数据旧的版本，而是生成一个新的版本
可伸缩性|很难实现横向扩展，纵向扩展的空间也比较有限|轻易地通过在集群中增加或者减少硬件数量来实现性能的伸缩

4.HBase有哪些类型的访问接口？
答：HBase提供了Native Java API , HBase Shell , Thrift Gateway , REST GateWay , Pig , Hive 等访问接口。

5.请以实例说明HBase数据模型。
![](https://s8.51cto.com/images/blog/202112/31111038_61ce74ae35bb553167.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

6.分别解释HBase中行键、列键和时间戳的概念
行键是唯一的，在一个表里只出现一次，否则就是在更新同一行，行键可以是任意的字节数组。
列族需要在创建表的时候就定义好。列族名必须由可打印字符组成，创建表的时候不需要定义好列。
时间戳，默认由系统指定，用户也可以显示设置。使用不同的时间戳来区分不同的版本。

7.请举个实例来阐述HBase的概念视图和物理视图的不同
HBase数据概念视图
![](https://s5.51cto.com/images/blog/202112/31111038_61ce74ae48bc959959.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

HBase数据物理视图
![](https://s7.51cto.com/images/blog/202112/31111038_61ce74ae587a948666.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)
在HBase的概念视图中，一个表可以视为一个稀疏、多维的映射关系。
在物理视图中，一个表会按照属于同一列族的数据保存在一起。

8.试述HBase各功能组建及其作用。
（1）库函数：链接到每个客户端；
（2）一个Master主服务器：主服务器Master主要负责表和Region的管理工作；
（3）许多个Region服务器：Region服务器是HBase中最核心的模块，负责维护分配给自己的Region，并响应用户的读写请求

9.请阐述HBase的数据分区机制。
答： HBase采用分区存储，一个大的表会被分拆许多个Region，这些Region会被分发到不同的服务器上实现分布式存储。

10.HBase中的分区是如何定位的。
答： 通过构建的映射表的每个条目包含两项内容，一个是Regionde 标识符，另一个是Region服务器标识，这个条目就标识Region和Region服务器之间的对应关系，从而就可以知道某个Region被保存在哪个Region服务器中。

11.试述HBase的三层结构中各层次的名称和作用。
![](https://s9.51cto.com/images/blog/202112/31111038_61ce74ae6a61046419.png?x-oss-process=image/watermark,size_16,text_QDUxQ1RP5Y2a5a6i,color_FFFFFF,t_30,g_se,x_10,y_10,shadow_20,type_ZmFuZ3poZW5naGVpdGk=)

12.请阐述HBase的三层结构下，客户端是如何访问到数据的。
答：首先访问Zookeeper，获取-ROOT表的位置信息，然后访问-Root-表，获得.MATA.表的信息，接着访问.MATA.表，找到所需的Region具体位于哪个Region服务器，最后才会到该Region服务器读取数据。

13.试述HBase系统基本架构以及每个组成部分的作用。
（1）客户端
客户端包含访问HBase的接口，同时在缓存中维护着已经访问过的Region位置信息，用来加快后续数据访问过程

（2）Zookeeper服务器
Zookeeper可以帮助选举出一个Master作为集群的总管，并保证在任何时刻总有唯一一个Master在运行，这就避免了Master的“单点失效”问题

（3）Master
主服务器Master主要负责表和Region的管理工作：管理用户对表的增加、删除、修改、查询等操作；实现不同Region服务器之间的负载均衡；在Region分裂或合并后，负责重新调整Region的分布；对发生故障失效的Region服务器上的Region进行迁移

（4）Region服务器
Region服务器是HBase中最核心的模块，负责维护分配给自己的Region，并响应用户的读写请求

14.请阐述Region服务器向HDFS文件系统中读写数据的基本原理。​
Region服务器内部管理一系列Region对象和一个HLog文件，其中，HLog是磁盘上面的记录文件，它记录着所有的更新操作。每个Region对象又是由多个Store组成的，每个Store对象了表中的一个列族的存储。每个Store又包含了MemStore和若干个StoreFile，其中，MemStore是在内存中的缓存。

15.试述HStore的工作原理
每个Store对应了表中的一个列族的存储。每个Store包括一个MenStore缓存和若干个StoreFile文件。MenStore是排序的内存缓冲区，当用户写入数据时，系统首先把数据放入MenStore缓存，当MemStore缓存满时，就会刷新到磁盘中的一个StoreFile文件中，当单个StoreFile文件大小超过一定阈值时，就会触发文件分裂操作。

16.试述HLog的工作原理
答：HBase系统为每个Region服务器配置了一个HLog文件，它是一种预写式日志（Write Ahead Log），用户更新数据必须首先写入日志后，才能写入MemStore缓存，并且，直到MemStore缓存内容对应的日志已经写入磁盘，该缓存内容才能被刷写到磁盘。
